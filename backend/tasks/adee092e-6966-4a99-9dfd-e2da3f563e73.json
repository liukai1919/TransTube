{
  "id": "adee092e-6966-4a99-9dfd-e2da3f563e73",
  "video_url": "https://www.youtube.com/watch?v=LAF-lACf2QY",
  "target_lang": "zh",
  "status": "completed",
  "progress": 100,
  "message": "处理完成",
  "stage": "embedding",
  "created_at": "2025-06-13T17:05:48.535035",
  "updated_at": "2025-06-13T17:07:55.016275",
  "result": {
    "video_url": "http://127.0.0.1:8000/static/videos/LAF-lACf2QY_sub.mp4",
    "srt_url": "http://127.0.0.1:8000/static/subtitles/LAF-lACf2QY_zh.srt",
    "download_url": "http://127.0.0.1:8000/static/videos/LAF-lACf2QY_sub.mp4",
    "duration": 541,
    "title": "Prompt engineering essentials: Getting better results from LLMs | Tutorial",
    "processing_method": "语音转录"
  },
  "output_path": "/home/liukai1919/TransTube-1/backend/static/videos/LAF-lACf2QY_sub.mp4",
  "srt_path": "/home/liukai1919/TransTube-1/backend/static/subtitles/LAF-lACf2QY_zh.srt",
  "video_info": {
    "filepath": "/home/liukai1919/TransTube-1/backend/downloads/LAF-lACf2QY.webm",
    "title": "Prompt engineering essentials: Getting better results from LLMs | Tutorial",
    "duration": 541,
    "filename": "LAF-lACf2QY.webm",
    "id": "LAF-lACf2QY",
    "uploader": "GitHub",
    "upload_date": "20250331",
    "thumbnail": "https://i.ytimg.com/vi_webp/LAF-lACf2QY/maxresdefault.webp",
    "description": "Struggling to get useful responses from AI models? This prompt engineering tutorial covers everything developers need to know for effective LLM interactions. Learn how to think about context and tokens, structure your requests, and overcome common prompt issues. Perfect for anyone looking to leverage AI more effectively in their development workflow.\n\n#PromptEngineering #AI #LLM\n\n— CHAPTERS — \n\n00:00 Intro to prompt engineering\n00:34 What are LLMs?\n01:06 Context, tokens, and limitations\n01:53 Understanding hallucinations and limitations\n02:25 What is a prompt?\n03:14 What is prompt engineering?\n03:41 Key components of effective prompting\n04:15 Refining a prompt example\n05:26 Handling prompt confusion and multi-step tasks\n06:17 Token limits and iterative prompting\n07:14 Being explicit and avoiding assumptions\n07:52 Final recap and takeaways\n\nWant to learn more? Visit:\nhttps://github.blog/ai-and-ml/github-copilot/github-for-beginners-how-to-get-llms-to-do-what-you-want\n\nStay up-to-date on all things GitHub by connecting with us:\n\nYouTube: https://gh.io/subgithub\nBlog: https://github.blog\nX: https://twitter.com/github\nLinkedIn: https://linkedin.com/company/github\nInsider newsletter: https://resources.github.com/newsletter/\nInstagram: https://www.instagram.com/github\nTikTok: https://www.tiktok.com/@github\n\nAbout GitHub\nIt’s where over 100 million developers create, share, and ship the best code possible. It’s a place for anyone, from anywhere, to build anything—it’s where the world builds software. https://github.com",
    "webpage_url": "https://www.youtube.com/watch?v=LAF-lACf2QY"
  },
  "completed_at": "2025-06-13T17:08:22.736056"
}