# TransTube æœ¬åœ°è¯­éŸ³ç¿»è¯‘æŒ‡å—

## æ¦‚è¿°

TransTube ç°åœ¨æ”¯æŒå®Œå…¨æœ¬åœ°åŒ–çš„è¯­éŸ³ç¿»è¯‘ç®¡é“ï¼Œå®ç° Aâ†’Bâ†’Câ†’D å®Œæ•´æµç¨‹ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   16 kHz WAV   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” Eng txt  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Zh txt  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Zh speech
â”‚  MIC/    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  ASR:     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  NMT:     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  TTS:    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ speakers
â”‚  FILE    â”‚               â”‚  Whisper  â”‚         â”‚  NLLB /   â”‚         â”‚  VITS /  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     A                         B                    C                     D
```

### æ¨èæ¨¡å‹é…ç½®

| é˜¶æ®µ | æ¨èæ¨¡å‹ | åŸå›  | GPUå†…å­˜ | å»¶è¿Ÿ |
|------|----------|------|---------|------|
| A-B | faster-whisper large-v3 | 4å€é€Ÿåº¦æå‡ï¼Œä¿æŒå‡†ç¡®æ€§ | 7.5GB | ~0.4x RT |
| B-C | nllb-200-distilled-1.3B | é«˜è´¨é‡å¤šè¯­è¨€ç¿»è¯‘ | 3.7GB | ~50ms/å¥ |
| C-D | VITS Chinese TTS | MITè®¸å¯ï¼Œæ”¯æŒå£°éŸ³å…‹éš† | 1-2GB | 20-40ms/å­—ç¬¦ |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# ç»™å®‰è£…è„šæœ¬æ‰§è¡Œæƒé™
chmod +x install_local_tts.sh

# è¿è¡Œå®‰è£…è„šæœ¬
./install_local_tts.sh
```

å®‰è£…è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
- æ£€æµ‹ç³»ç»Ÿç¯å¢ƒï¼ˆPythonç‰ˆæœ¬ã€CUDAæ”¯æŒï¼‰
- å®‰è£…æ‰€éœ€çš„PythonåŒ…
- ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
- é…ç½®ç¯å¢ƒå˜é‡

### 2. æ‰‹åŠ¨å®‰è£…ï¼ˆå¯é€‰ï¼‰

å¦‚æœè‡ªåŠ¨å®‰è£…å¤±è´¥ï¼Œå¯ä»¥æ‰‹åŠ¨å®‰è£…ï¼š

```bash
# å®‰è£… PyTorch (æ ¹æ®ä½ çš„CUDAç‰ˆæœ¬)
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121  # CUDA 12.1
# æˆ–
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118  # CUDA 11.8
# æˆ–
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu    # CPU only

# å®‰è£…æœ¬åœ°TTSä¾èµ–
pip install -r backend/requirements_local_tts.txt
```

### 3. é…ç½®ç¯å¢ƒå˜é‡

åœ¨ `.env` æ–‡ä»¶ä¸­æ·»åŠ ï¼š

```bash
# å¯ç”¨æœ¬åœ° TTS
USE_LOCAL_TTS=true

# æ¨¡å‹é…ç½®
WHISPER_MODEL_SIZE=large-v3
TRANSLATION_MODEL=nllb-200-distilled-1.3B
LOCAL_TTS_MODEL=tts_models/zh-CN/baker/tacotron2-DDC-GST

# è®¾å¤‡é…ç½®ï¼ˆå¯é€‰ï¼‰
TORCH_DEVICE=auto  # auto, cpu, cuda
```

## ğŸ“‹ ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•ä¸€ï¼šé€šè¿‡ Web ç•Œé¢

1. å¯åŠ¨ TransTube æœåŠ¡
2. åœ¨å¤„ç†è§†é¢‘æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨æœ¬åœ° TTS
3. æŸ¥çœ‹å¤„ç†æ—¥å¿—ç¡®è®¤ä½¿ç”¨çš„æ˜¯æœ¬åœ°æ¨¡å‹

### æ–¹æ³•äºŒï¼šé€šè¿‡ API

#### æ£€æŸ¥æœ¬åœ° TTS çŠ¶æ€
```bash
curl http://localhost:8000/api/local-tts-status
```

#### æµ‹è¯•æœ¬åœ° TTS ç®¡é“
```bash
curl -X POST "http://localhost:8000/api/test-local-tts" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "text=Hello, this is a test&source_lang=en&target_lang=zh"
```

#### ä½¿ç”¨æœ¬åœ° TTS å¤„ç†è§†é¢‘
```bash
curl -X POST "http://localhost:8000/api/process-with-local-tts" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "video_url=https://www.youtube.com/watch?v=VIDEO_ID&use_local_tts=true"
```

### æ–¹æ³•ä¸‰ï¼šPython ä»£ç è°ƒç”¨

```python
from backend.utils.local_tts import LocalSpeechTranslationPipeline

# åˆ›å»ºç®¡é“
pipeline = LocalSpeechTranslationPipeline(
    whisper_model_size="large-v3",
    translation_model="nllb-200-distilled-1.3B",
    tts_model="tts_models/zh-CN/baker/tacotron2-DDC-GST",
    device="auto"
)

# å¤„ç†éŸ³é¢‘æ–‡ä»¶
output_audio = pipeline.process_audio_to_audio(
    input_audio_path="input.wav",
    source_lang="en",
    target_lang="zh"
)

# å¤„ç†è§†é¢‘æ–‡ä»¶
chinese_audio = pipeline.process_video_to_chinese_audio("video.mp4")
```

## âš™ï¸ é«˜çº§é…ç½®

### æ¨¡å‹é€‰æ‹©

#### Whisper æ¨¡å‹å¤§å°
```python
# é€Ÿåº¦ vs å‡†ç¡®æ€§æƒè¡¡
whisper_models = {
    "tiny": "æœ€å¿«ï¼Œå‡†ç¡®æ€§è¾ƒä½",
    "base": "å¿«é€Ÿï¼ŒåŸºæœ¬å‡†ç¡®æ€§", 
    "small": "å¹³è¡¡é€‰æ‹©",
    "medium": "è¾ƒå¥½å‡†ç¡®æ€§",
    "large-v3": "æœ€ä½³å‡†ç¡®æ€§ï¼ˆæ¨èï¼‰"
}
```

#### ç¿»è¯‘æ¨¡å‹é€‰æ‹©
```python
translation_models = {
    "nllb-200-distilled-1.3B": "æ¨èï¼Œå¹³è¡¡æ€§èƒ½å’Œè´¨é‡",
    "nllb-200-distilled-600M": "æ›´å¿«ï¼Œè´¨é‡ç¨ä½",
    "nllb-200-3.3B": "æœ€é«˜è´¨é‡ï¼Œéœ€è¦æ›´å¤šå†…å­˜"
}
```

#### TTS æ¨¡å‹é€‰æ‹©
```python
tts_models = {
    "tts_models/zh-CN/baker/tacotron2-DDC-GST": "æ¨èä¸­æ–‡æ¨¡å‹",
    "tts_models/multilingual/multi-dataset/your_tts": "å¤šè¯­è¨€æ”¯æŒ",
    "tts_models/zh-CN/baker/glow-tts": "æ›´å¿«çš„ä¸­æ–‡æ¨¡å‹"
}
```

### æ€§èƒ½ä¼˜åŒ–

#### GPU å†…å­˜ä¼˜åŒ–
```python
# åœ¨ local_tts.py ä¸­è°ƒæ•´
pipeline = LocalSpeechTranslationPipeline(
    whisper_model_size="medium",  # ä½¿ç”¨è¾ƒå°æ¨¡å‹
    device="cuda"
)

# è®¾ç½® PyTorch å†…å­˜åˆ†é…
import torch
torch.cuda.set_per_process_memory_fraction(0.8)
```

#### æ‰¹å¤„ç†ä¼˜åŒ–
```python
# å¤„ç†å¤šä¸ªéŸ³é¢‘æ–‡ä»¶
for audio_file in audio_files:
    result = pipeline.process_audio_to_audio(audio_file)
    # å¤„ç†ç»“æœ...
```

### è‡ªå®šä¹‰é…ç½®

#### åˆ›å»ºè‡ªå®šä¹‰ç®¡é“
```python
class CustomSpeechPipeline(LocalSpeechTranslationPipeline):
    def __init__(self):
        super().__init__(
            whisper_model_size="medium",
            translation_model="nllb-200-distilled-600M",
            tts_model="tts_models/zh-CN/baker/glow-tts",
            device="cuda"
        )
    
    def custom_preprocessing(self, audio_path):
        # è‡ªå®šä¹‰éŸ³é¢‘é¢„å¤„ç†
        pass
    
    def custom_postprocessing(self, result):
        # è‡ªå®šä¹‰ç»“æœåå¤„ç†
        pass
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. æ¨¡å‹ä¸‹è½½å¤±è´¥
```bash
# æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹
python -c "
from faster_whisper import WhisperModel
model = WhisperModel('large-v3', device='cpu')
"
```

#### 2. CUDA å†…å­˜ä¸è¶³
```bash
# ä½¿ç”¨è¾ƒå°æ¨¡å‹æˆ–CPUæ¨¡å¼
export WHISPER_MODEL_SIZE=medium
export TORCH_DEVICE=cpu
```

#### 3. ç¿»è¯‘è´¨é‡ä¸ä½³
```python
# è°ƒæ•´ç¿»è¯‘å‚æ•°
pipeline.translation_model.generate(
    **inputs,
    num_beams=10,  # å¢åŠ beam search
    temperature=0.1,  # é™ä½éšæœºæ€§
    max_length=1024  # å¢åŠ æœ€å¤§é•¿åº¦
)
```

#### 4. è¯­éŸ³åˆæˆé€Ÿåº¦æ…¢
```bash
# ä½¿ç”¨æ›´å¿«çš„TTSæ¨¡å‹
LOCAL_TTS_MODEL=tts_models/zh-CN/baker/glow-tts
```

### æ—¥å¿—è°ƒè¯•

```python
import logging
logging.basicConfig(level=logging.DEBUG)

# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
pipeline = LocalSpeechTranslationPipeline()
result = pipeline.process_audio_to_audio("test.wav")
```

### æ€§èƒ½ç›‘æ§

```python
import time
import psutil
import torch

def monitor_performance():
    # CPUä½¿ç”¨ç‡
    cpu_percent = psutil.cpu_percent()
    
    # å†…å­˜ä½¿ç”¨
    memory = psutil.virtual_memory()
    
    # GPUä½¿ç”¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.memory_allocated()
        
    print(f"CPU: {cpu_percent}%, Memory: {memory.percent}%")
    if torch.cuda.is_available():
        print(f"GPU Memory: {gpu_memory / 1024**3:.2f}GB")
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### å¤„ç†æ—¶é—´å¯¹æ¯”ï¼ˆ10åˆ†é’Ÿè§†é¢‘ï¼‰

| æ–¹æ³• | ASR | ç¿»è¯‘ | TTS | æ€»æ—¶é—´ |
|------|-----|------|-----|--------|
| äº‘æœåŠ¡ | 30s | 10s | 20s | 60s |
| æœ¬åœ°CPU | 180s | 45s | 90s | 315s |
| æœ¬åœ°GPU | 45s | 15s | 30s | 90s |

### è´¨é‡å¯¹æ¯”

| æŒ‡æ ‡ | äº‘æœåŠ¡ | æœ¬åœ°æ¨¡å‹ |
|------|--------|----------|
| ASRå‡†ç¡®ç‡ | 95% | 93% |
| ç¿»è¯‘è´¨é‡ | 90% | 88% |
| è¯­éŸ³è‡ªç„¶åº¦ | 95% | 85% |
| éšç§ä¿æŠ¤ | âŒ | âœ… |
| ç¦»çº¿å¯ç”¨ | âŒ | âœ… |

## ğŸ”„ ç‰ˆæœ¬æ›´æ–°

### æ›´æ–°æ¨¡å‹
```bash
# æ¸…é™¤æ¨¡å‹ç¼“å­˜
rm -rf ~/.cache/whisper
rm -rf ~/.cache/huggingface
rm -rf ~/.cache/tts

# é‡æ–°ä¸‹è½½æœ€æ–°æ¨¡å‹
./install_local_tts.sh
```

### æ›´æ–°ä»£ç 
```bash
git pull origin main
pip install -r backend/requirements_local_tts.txt --upgrade
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®æ–°çš„æ¨¡å‹æ”¯æŒæˆ–æ€§èƒ½ä¼˜åŒ–ï¼š

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æ·»åŠ æ–°æ¨¡å‹æ”¯æŒ
4. æäº¤ Pull Request

### æ·»åŠ æ–°çš„ TTS æ¨¡å‹

```python
# åœ¨ local_tts.py ä¸­æ·»åŠ 
def _init_custom_tts_model(self):
    """åˆå§‹åŒ–è‡ªå®šä¹‰ TTS æ¨¡å‹"""
    try:
        # ä½ çš„è‡ªå®šä¹‰TTSæ¨¡å‹åˆå§‹åŒ–ä»£ç 
        pass
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–è‡ªå®šä¹‰TTSæ¨¡å‹å¤±è´¥: {str(e)}")
```

## ğŸ“š å‚è€ƒèµ„æ–™

- [faster-whisper æ–‡æ¡£](https://github.com/guillaumekln/faster-whisper)
- [NLLB æ¨¡å‹](https://huggingface.co/facebook/nllb-200-distilled-1.3B)
- [Coqui TTS æ–‡æ¡£](https://docs.coqui.ai/)
- [PyTorch ä¼˜åŒ–æŒ‡å—](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html)

## ğŸ“„ è®¸å¯è¯

æœ¬åœ° TTS åŠŸèƒ½ä½¿ç”¨çš„æ¨¡å‹è®¸å¯è¯ï¼š
- faster-whisper: MIT License
- NLLB: CC-BY-NC License
- VITS: MIT License

è¯·ç¡®ä¿éµå®ˆç›¸åº”çš„è®¸å¯è¯è¦æ±‚ã€‚ 